{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Approfondissement ElasticSearch pour des recherches de proximité\n",
        "\n",
        "géographique\n",
        "\n",
        "Lino Galiana  \n",
        "2025-03-19\n",
        "\n",
        "Pour essayer les exemples présents dans ce tutoriel :\n",
        "\n",
        "Ce chapitre est issu du travail produit\n",
        "dans le cadre d’un hackathon de l’Insee avec\n",
        "[Raphaële Adjerad](https://github.com/raphaeleadjerad)\n",
        "et présente quelques éléments qui peuvent être utiles\n",
        "pour l’enrichissement de données d’entreprises\n",
        "à partir d’un répertoire officiel.\n",
        "\n",
        ":warning: Il nécessite une version particulière du package `elasticsearch` pour tenir compte de l’héritage de la version 7 du moteur Elastic. Pour cela, faire\n",
        "\n",
        "``` python\n",
        "pip install elasticsearch==8.2.0\n",
        "```\n",
        "\n",
        "# 1. Introduction\n",
        "\n",
        "Dans le cadre particulier de l’identification des entreprises, Elasticsearch fait partie de la solution retenue par\n",
        "l’API “Sirene données ouvertes” (DINUM) (cf https://annuaire-entreprises.data.gouv.fr/) l’API de recherche d’entreprises Française de la Fabrique numérique des Ministères Sociaux (cf https://api.recherche-entreprises.fabrique.social.gouv.fr/)le projet de l’Insee “Amélioration de l’identification de l’employeur dans le recensement”, pour faire une première sélection des établissements pertinents pour un bulletin de recensement donné.\n",
        "Dans le cadre de l’identification des individus, Elasticsearch fait partie de la solution envisagée pour l’identification des individus au RNIPP (Répertoire national des personnes physiques) pour le projet CSNS (Code statistique non signifiant), et est la solution technique sous-jacente au projet matchID du ministère de l’intérieur.\n",
        "\n",
        "Au delà du secteur public, on peut citer qu’Amazon AWS fait partie des utilisateurs historiques d’Elasticsearch.\n",
        "\n",
        "## 1.1 Objectif\n",
        "\n",
        "Ce chapitre vise à approfondir les éléments présentés sur Elastic précédemment. L’idée\n",
        "est de se placer dans un contexte opérationnel où on reçoit des informations\n",
        "sur des entreprises telles que l’adresse et la localisation et qu’on\n",
        "désire associer à des données administratives considérées plus fliables.\n",
        "\n",
        "## 1.2 Réplication de ce chapitre\n",
        "\n",
        "Comme le précédent, ce chapitre est plus exigeant en termes d’infrastructures que les précédents.\n",
        "Il nécessite un serveur Elastic. Les utilisateurs du\n",
        "[SSP Cloud](datalab.sspcloud.fr/) pourront répliquer les exemples de ce cours\n",
        "car cette technologie est disponible (que ce soit pour indexer une base ou\n",
        "pour requêter une base existante).\n",
        "\n",
        "La première partie de ce tutoriel, qui consiste à créer une base Sirene géolocalisée\n",
        "à partir des données *open-data* ne nécessite pas d’architecture particulière et\n",
        "peut ainsi être exécutée en utilisant les packages suivants :"
      ],
      "id": "94569773-5a42-467d-9be4-12e398e9073d"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "id": "33279b3c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1.3 Sources\n",
        "\n",
        "Ce chapitre va utiliser plusieurs sources de diffusion de\n",
        "l’Insee:\n",
        "\n",
        "-   Le stock des établissements présents dans les [données de diffusion Sirene](https://www.insee.fr/fr/information/3591226) ;\n",
        "-   Les [données Sirene géolocalisées](https://www.data.gouv.fr/fr/datasets/geolocalisation-des-etablissements-du-repertoire-sirene-pour-les-etudes-statistiques/)\n",
        "\n",
        "Les données à siretiser sont celles du registre Français des émissions polluantes\n",
        "établi par le Ministère de la Transition Energétique. Le jeu de données\n",
        "est disponible sur [data.gouv](https://www.data.gouv.fr/fr/datasets/registre-francais-des-emissions-polluantes/)\n",
        "\n",
        "# 2. Préparation des données à identifier\n",
        "\n",
        "Le jeu de données présente déjà\n",
        "l’identifiant\n",
        "de l’établissement, dit numéro `siret`.\n",
        "Nous allons faire comme si nous étions\n",
        "en amont de cet appariement et que nous\n",
        "désirons trouver ce numéro. La présence\n",
        "dans la base de ce numéro nous permettra d’évaluer la qualité\n",
        "de notre méthode de recherche avec\n",
        "`Elastic`."
      ],
      "id": "b871066a-2295-438a-8f2f-21c5eb936b70"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "\n",
        "url = \"https://www.data.gouv.fr/fr/datasets/r/9af639b9-e2b6-4d7d-8c5f-0c4953c48663\"\n",
        "req = requests.get(url)\n",
        "\n",
        "with open(\"irep.zip\",'wb') as f:\n",
        "  f.write(req.content)\n",
        "\n",
        "with zipfile.ZipFile(\"irep.zip\", 'r') as zip_ref:\n",
        "  zip_ref.extractall(\"irep\")\n",
        "\n",
        "etablissements = pd.read_csv(\"irep/2019/etablissements.csv\", sep = \";\")"
      ],
      "id": "2277cd0d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Constitution du référentiel administratif géolocalisé\n",
        "\n",
        "Dans un premier temps, on va combiner ensemble les différentes sources\n",
        "*open-data* pour créer un référentiel fiable d’entreprises\n",
        "géolocalisées.\n",
        "\n",
        "## 3.1 Importer la base déjà créée\n",
        "\n",
        "Les données à utiliser pour constuire une base Sirene géolocalisée\n",
        "sont trop volumineuses pour les serveurs mis à disposition\n",
        "gratuitement par `Github` pour la compilation de ce site web.\n",
        "Nous proposons ainsi une version déjà construite, stockée\n",
        "dans l’espace de mise à disposition du SSP Cloud. Ce fichier est\n",
        "au format `parquet` et est ouvert à\n",
        "tous, même pour les personnes ne disposant pas d’un compte.\n",
        "Le code ayant construit cette base est présenté ci-dessous.\n",
        "\n",
        "Pour importer cette base, on utilise les fonctionalités\n",
        "de `pyarrow` qui permettent d’importer un fichier sur\n",
        "un système de stockage *cloud* comme s’il était\n",
        "présent sur le disque :"
      ],
      "id": "43a30a48-b20a-4784-a896-cd51983d2633"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyarrow import fs\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "bucket = \"lgaliana\"\n",
        "path = \"diffusion/sirene_geolocalized.parquet\"\n",
        "\n",
        "s3 = fs.S3FileSystem(endpoint_override=\"http://\"+\"minio.lab.sspcloud.fr\")\n",
        "\n",
        "df_geolocalized = pq.ParquetDataset(f'{bucket}/{path}', filesystem=s3).read_pandas().to_pandas()\n",
        "df_geolocalized.head(3)"
      ],
      "id": "607a7ae0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2 Reproduire la construction de la base\n",
        "\n",
        "La première base d’entrée à utiliser est disponible sur\n",
        "[data.gouv](https://www.data.gouv.fr/fr/datasets/base-sirene-des-entreprises-et-de-leurs-etablissements-siren-siret/)"
      ],
      "id": "0386c3c7-1fa6-4e1b-b2be-e9c3554f362e"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import zipfile\n",
        "\n",
        "url_download = \"https://www.data.gouv.fr/fr/datasets/r/0651fb76-bcf3-4f6a-a38d-bc04fa708576\"\n",
        "req = requests.get(url_download)\n",
        "\n",
        "with open(\"sirene.zip\",'wb') as f:\n",
        "  f.write(req.content)\n",
        "\n",
        "with zipfile.ZipFile(\"sirene.zip\", 'r') as zip_ref:\n",
        "  zip_ref.extractall(\"sirene\")"
      ],
      "id": "5ba9d3ab"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On va importer seulement les colonnes utiles et simplifier la structure\n",
        "pour être en mesure de ne garder que les informations qui nous\n",
        "intéressent (nom de l’entreprise, adresse, commune, code postal…)"
      ],
      "id": "0668e678-6a04-4d87-9227-245332999de9"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "list_cols = [\n",
        "  'siren', 'siret',\n",
        "  'activitePrincipaleRegistreMetiersEtablissement',\n",
        "  'complementAdresseEtablissement',\n",
        "  'numeroVoieEtablissement',\n",
        "  'typeVoieEtablissement',\n",
        "  'libelleVoieEtablissement',\n",
        "  'codePostalEtablissement',\n",
        "  'libelleCommuneEtablissement',\n",
        "  'codeCommuneEtablissement',\n",
        "  'etatAdministratifEtablissement',\n",
        "  'denominationUsuelleEtablissement',\n",
        "  'activitePrincipaleEtablissement'\n",
        "]\n",
        "\n",
        "df = pd.read_csv(\n",
        "  \"sirene/StockEtablissement_utf8.csv\",\n",
        "  usecols = list_cols)\n",
        "\n",
        "df['numero'] = df['numeroVoieEtablissement']\\\n",
        "  .replace('-', np.NaN).str.split().str[0]\\\n",
        "  .str.extract('(\\d+)', expand=False)\\\n",
        "  .fillna(\"0\").astype(int)\n",
        "\n",
        "df['numero'] = df['numero'].astype(str).replace(\"0\",\"\")\n",
        "\n",
        "df['adresse'] = df['numero'] + \" \" + \\\n",
        "  df['typeVoieEtablissement'] + \" \" + \\\n",
        "  df['libelleVoieEtablissement']\n",
        "\n",
        "df['adresse'] = df['adresse'].replace(np.nan, \"\")\n",
        "\n",
        "df = df.loc[df['etatAdministratifEtablissement'] == \"A\"]\n",
        "\n",
        "df.rename(\n",
        "  {\"denominationUsuelleEtablissement\": \"denom\",\n",
        "  \"libelleCommuneEtablissement\": \"commune\",\n",
        "  \"codeCommuneEtablissement\" : \"code_commune\",\n",
        "  \"codePostalEtablissement\": \"code_postal\"},\n",
        "  axis = \"columns\", inplace = True)\n",
        "\n",
        "df['ape'] = df['activitePrincipaleEtablissement'].str.replace(\"\\.\", \"\", regex = True)\n",
        "df['denom'] = df[\"denom\"].replace(np.nan, \"\")\n",
        "\n",
        "df_siret = df.loc[:, ['siren', 'siret','adresse', 'ape', 'denom', 'commune', 'code_commune','code_postal']]\n",
        "df_siret['code_postal'] = df_siret['code_postal'].replace(np.nan, \"0\").astype(int).astype(str).replace(\"0\",\"\")"
      ],
      "id": "cadc2009"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On importe ensuite les données géolocalisées"
      ],
      "id": "44dd7794-51fe-44bd-9a85-dd6c5b1a5f0a"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import shutil\n",
        "import os\n",
        "\n",
        "#os.remove(\"sirene.zip\")\n",
        "#shutil.rmtree('sirene/')\n",
        "\n",
        "url_geoloc = \"https://files.data.gouv.fr/insee-sirene-geo/GeolocalisationEtablissement_Sirene_pour_etudes_statistiques_utf8.zip\"\n",
        "r = requests.get(url_geoloc)  \n",
        "\n",
        "with open('geoloc.zip', 'wb') as f:\n",
        "    f.write(r.content)\n",
        "\n",
        "with zipfile.ZipFile(\"geoloc.zip\", 'r') as zip_ref:\n",
        "  zip_ref.extractall(\"geoloc\")\n",
        "\n",
        "df_geoloc = pd.read_csv(\n",
        "  \"geoloc/GeolocalisationEtablissement_Sirene_pour_etudes_statistiques_utf8.csv\",\n",
        "  usecols = [\"siret\", \"epsg\", \"x_longitude\", \"y_latitude\"] , sep = \";\")"
      ],
      "id": "fdda2c6e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il ne reste plus qu’à associer les deux jeux de données"
      ],
      "id": "9e01351d-95c7-48a6-a217-bfd6137d0057"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geolocalized = df_siret.merge(df_geoloc, on = \"siret\") \n",
        "df_geolocalized['code_commune'] = df_geolocalized['code_commune'].astype(str) "
      ],
      "id": "77833a1d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Si vous avez accès à un espace de stockage cloud de type\n",
        "`S3`, il est possible d’utiliser `pyarrow` pour enregister\n",
        "cette base. Afin de l’enregistrer dans un espace de stockage\n",
        "public, nous allons l’enregistrer dans un dossier `diffusion`[1]\n",
        "\n",
        "[1] Concernant la première piste, il aurait\n",
        "fallu mieux définir notre mapping pour\n",
        "autoriser des *analyzers*. A défaut,\n",
        "nous pourrons\n",
        "utiliser `nltk` ou `spacy` pour transformer\n",
        "les champs textuels avant d’envoyer la requête.\n",
        "Cette solution présente l’inconvénient\n",
        "de ne pas formatter de la même manière l’ensemble\n",
        "indexé mais pourrait malgré tout améliorer la pertinence\n",
        "des recherches."
      ],
      "id": "2c6e1f36-6b46-401e-a2e5-356e6122fc2d"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pyarrow import fs\n",
        "import pyarrow as pa\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "bucket = \"lgaliana\"\n",
        "path = \"diffusion/sirene_geolocalized.parquet\"\n",
        "\n",
        "s3 = fs.S3FileSystem(endpoint_override=\"http://\"+\"minio.lab.sspcloud.fr\")\n",
        "\n",
        "table = pa.Table.from_pandas(df_geolocalized)"
      ],
      "id": "373c670e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. Connexion à ElasticSearch\n",
        "\n",
        "On va supposer que l’utilisateur dispose déjà d’un serveur Elastic\n",
        "fonctionnel mais désire créer un nouvel index. Si vous utilisez\n",
        "le SSPCloud, la démarche de création d’un service\n",
        "Elastic est disponible dans le chapitre précédent."
      ],
      "id": "ee1d8a2f-bfc2-4543-bf50-b2623b4f7938"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "from elasticsearch import Elasticsearch\n",
        "HOST = 'elasticsearch-master'\n",
        "\n",
        "def elastic():\n",
        "    \"\"\"Connection avec Elastic sur le data lab\"\"\"\n",
        "    es = Elasticsearch([{'host': HOST, 'port': 9200, 'scheme': 'http'}], http_compress=True, request_timeout=200)\n",
        "    return es\n",
        "\n",
        "es = elastic()\n",
        "es"
      ],
      "id": "20c957b3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    <Elasticsearch(['http://elasticsearch-master:9200'])>\n",
        "\n",
        "# 5. Indexation de notre base Sirène géolocalisée\n",
        "\n",
        "## 5.1 Définition du mapping\n",
        "\n",
        "On va procéder par étape en essayant d’utiliser la structure la plus simple\n",
        "possible.\n",
        "\n",
        ":one: On s’occupe d’abord de définir le *mapping*\n",
        "pour les variables textuelles."
      ],
      "id": "b064c22f-49e0-479c-9ea5-b5fcf7170211"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "string_var = [\"adresse\", \"denom\", \"ape\", \"commune\"]\n",
        "map_string = {\"type\": \"text\", \"fields\": {\"keyword\": {\"type\": \"keyword\", \"ignore_above\": 256}}}\n",
        "mapping_string = {l: map_string for l in string_var}"
      ],
      "id": "37cfd844"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":two: Les variables catégorielles sont utilisées\n",
        "par le biais du type `keyword`:"
      ],
      "id": "57a4ee4e-b752-4321-bd9a-2f9815f8aed0"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# keywords\n",
        "keyword_var = [\"siren\",\"siret\",\"code_commune\",\"code_postal\"]\n",
        "map_keywords = {'type': 'text', 'fields': {'keyword': {'type': 'keyword', 'ignore_above': 256}}}\n",
        "mapping_keywords = {l: map_keywords for l in keyword_var}"
      ],
      "id": "ddb568d6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ":three: La nouveauté par rapport à la partie\n",
        "précédente est l’utilisation de la\n",
        "dimension géographique. `Elastic` propose\n",
        "le type `geo_point` pour cela."
      ],
      "id": "33ea8b4d-fd06-466a-8cf8-2a7909f92e0a"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# geoloc\n",
        "mapping_geoloc = {\n",
        "  \"location\": {\n",
        "    \"type\": \"geo_point\"\n",
        "    }\n",
        "}    "
      ],
      "id": "ab88f609"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On collecte tout cela ensemble dans un\n",
        "dictionnaire:"
      ],
      "id": "0f4bc1b1-aac6-4b88-84a1-8a92494bbf37"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# mapping\n",
        "mapping_elastic = {\"mappings\":\n",
        "  {\"properties\":\n",
        "    {**mapping_string, **mapping_geoloc, **mapping_keywords}\n",
        "  }\n",
        "}"
      ],
      "id": "c9640c86"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Il est tout à fait possible de définir un *mapping*\n",
        "plus raffiné. Ici, on va privilégier\n",
        "l’utilisation d’un *mapping* simple pour\n",
        "illustrer la recherche par distance\n",
        "géographique en priorité.\n",
        "\n",
        "## 5.2 Création de l’index\n",
        "\n",
        "Pour créer le nouvel index, on s’assure d’abord de ne pas\n",
        "déjà l’avoir créé et on passe le *mapping* défini\n",
        "précédemment."
      ],
      "id": "4e0265ea-e276-4384-bc0c-dea58025fdb7"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "if es.indices.exists('sirene'):\n",
        "    es.indices.delete('sirene')\n",
        "\n",
        "es.indices.create(index = \"sirene\", body = mapping_elastic)   "
      ],
      "id": "72a8aa2e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.3 Indexation de la base géolocalisée\n",
        "\n",
        "Pour le moment, l’index est vide. Il convient de\n",
        "le peupler.\n",
        "\n",
        "Il est néanmoins nécessaire de créer le champ `location`\n",
        "au format attendu par elastic: `lat, lon` à partir\n",
        "de nos colonnes."
      ],
      "id": "2d3f1d75-3bbe-40f9-8b70-5a560c90e9de"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_geolocalized['location'] = df_geolocalized['y_latitude'].astype(str) + \", \" + df_geolocalized['x_longitude'].astype(str)"
      ],
      "id": "6216ef49"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La fonction suivante permet de structurer chaque\n",
        "ligne du `DataFrame` telle qu’Elastic l’attend:"
      ],
      "id": "7748c2a8-29e1-4aef-9715-6a33c6d255bb"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gen_dict_from_pandas(index_name, df):\n",
        "    '''\n",
        "    Lit un dataframe pandas Open Food Facts, renvoi un itérable = dictionnaire des données à indexer, sous l'index fourni\n",
        "    '''\n",
        "    for i, row in df.iterrows():\n",
        "        header= {\"_op_type\": \"index\",\"_index\": index_name,\"_id\": i}\n",
        "        yield {**header,**row}"
      ],
      "id": "3b802ba0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Enfin, on peut industrialiser l’indexation\n",
        "de notre `DataFrame` en faisant tourner de\n",
        "manière successive cette fonction :"
      ],
      "id": "8e6a934e-cf2c-4da1-8104-887811343b27"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "from elasticsearch.helpers import bulk, parallel_bulk\n",
        "from collections import deque\n",
        "deque(parallel_bulk(client=es, actions=gen_dict_from_pandas(\"sirene\", df_geolocalized), chunk_size = 1000, thread_count = 4))"
      ],
      "id": "6f73e1e3"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "es.count(index = 'sirene')"
      ],
      "id": "7fbed58d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    ObjectApiResponse({'count': 13059694, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}})\n",
        "\n",
        "# 6. Recherche\n",
        "\n",
        "Pour se faciliter la création de cartes\n",
        "réactives, nous allons régulièrement\n",
        "utiliser la fonction suivante qui s’appuie\n",
        "sur un code déjà présenté dans un autre\n",
        "chapitre."
      ],
      "id": "fbc817e4-18f5-4a9e-bfbd-6eac0ed7fd93"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def plot_folium_sirene(df, yvar, xvar):\n",
        "\n",
        "    center = df[[yvar, xvar]].mean().values.tolist()\n",
        "    sw = df[[yvar, xvar]].min().values.tolist()\n",
        "    ne = df[[yvar, xvar]].max().values.tolist()\n",
        "\n",
        "    m = folium.Map(location = center, tiles='OpenStreetMap')\n",
        "\n",
        "    # I can add marker one by one on the map\n",
        "    for i in range(0,len(df)):\n",
        "        folium.Marker(\n",
        "            [df.iloc[i][yvar], df.iloc[i][xvar]],\n",
        "            popup = df.iloc[i][\"_source.denom\"] + f'<br>(Score: {df.iloc[i][\"_score\"]:.2f})',\n",
        "            icon=folium.Icon(icon=\"home\")\n",
        "        ).add_to(m)\n",
        "\n",
        "    m.fit_bounds([sw, ne])\n",
        "\n",
        "    return m"
      ],
      "id": "fe0ed252"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6.1 Premier exemple de requête géographique"
      ],
      "id": "77eb8743-428d-49ec-bde2-33dc7775fb5a"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "ex1 = es.search(index = 'sirene', body = '''{\n",
        "  \"query\": {\n",
        "    \"bool\": {\n",
        "      \"must\":\n",
        "      { \"match\": { \"denom\":   \"institut national de la statistique\"}}\n",
        "      }\n",
        "  }\n",
        "}\n",
        "''')['hits']['hits']\n",
        "\n",
        "echo_insee = pd.json_normalize(ex1)\n",
        "echo_insee"
      ],
      "id": "0363d977"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On remarque déjà que les intitulés ne sont\n",
        "pas bons. Quand est-il de leurs localisations ?"
      ],
      "id": "0799b646-09ff-4bdb-91e2-f1fd14876c66"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_folium_sirene(\n",
        "  echo_insee, yvar = \"_source.y_latitude\",\n",
        "  xvar = \"_source.x_longitude\")"
      ],
      "id": "c1c7b80d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ce premier essai nous suggère qu’il est\n",
        "nécessaire d’améliorer notre recherche.\n",
        "Plusieurs voies sont possibles:\n",
        "\n",
        "1.  Améliorer le preprocessing de nos champs\n",
        "    textuels en excluant, par exemple, les\n",
        "    stopwords ;\n",
        "2.  Effectuer une restriction géographique\n",
        "    pour mieux cibler l’ensemble de recherche\n",
        "3.  Trouver une variable catégorielle jouant\n",
        "    le rôle de variable de blocage[1] pour\n",
        "    mieux cibler les paires pertinentes\n",
        "\n",
        "Concernant la restriction\n",
        "géographique, Elastic fournit une approche\n",
        "très efficace de ciblage géographique.\n",
        "En connaissant une position approximative\n",
        "de l’entreprise à rechercher,\n",
        "il est ainsi possible de\n",
        "rechercher dans un rayon\n",
        "d’une taille plus ou moins grande.\n",
        "En supposant qu’on connaisse précisément\n",
        "la localisation de l’Insee, on peut\n",
        "chercher dans un rayon relativement\n",
        "restreint. Si notre position était plus\n",
        "approximative, on pourrait rechercher\n",
        "dans un rayon plus large.\n",
        "\n",
        "[1] Concernant la première piste, il aurait\n",
        "fallu mieux définir notre mapping pour\n",
        "autoriser des *analyzers*. A défaut,\n",
        "nous pourrons\n",
        "utiliser `nltk` ou `spacy` pour transformer\n",
        "les champs textuels avant d’envoyer la requête.\n",
        "Cette solution présente l’inconvénient\n",
        "de ne pas formatter de la même manière l’ensemble\n",
        "indexé mais pourrait malgré tout améliorer la pertinence\n",
        "des recherches."
      ],
      "id": "c7c3cad5-c4fa-4334-ba89-c98e49b4df9e"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "ex2 = es.search(index = 'sirene', body = '''{\n",
        "  \"query\": {\n",
        "    \"bool\": {\n",
        "      \"must\":\n",
        "      { \"match\": { \"denom\":   \"institut national de la statistique\"}}\n",
        "      ,\n",
        "      \"filter\":\n",
        "        {\"geo_distance\": {\n",
        "          \"distance\": \"1km\",\n",
        "          \"location\": {\n",
        "            \"lat\": \"48.8168\",\n",
        "            \"lon\": \"2.3099\"\n",
        "          }\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "''')['hits']['hits']\n",
        "\n",
        "echo_insee = pd.json_normalize(ex2)\n",
        "echo_insee"
      ],
      "id": "021e747b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-warning\" role=\"alert\">\n",
        "<h3 class=\"alert-heading\"><i class=\"fa-solid fa-lightbulb\"></i> Hint</h3>\n",
        "\n",
        "Connaître la localisation précise d’une\n",
        "entreprise\n",
        "nécessite déjà une bonne remontée\n",
        "d’information sur celle-ci.\n",
        "Il est plus plausible de supposer\n",
        "qu’on dispose, dans une phase amont\n",
        "de la chaine de production,\n",
        "de l’adresse de celle-ci.\n",
        "Dans ce cas, il est utile\n",
        "d’utiliser un service de géocodage,\n",
        "comme l’[API Adresse](https://adresse.data.gouv.fr/api-doc/adresse)\n",
        "développée par Etalab.\n",
        "\n",
        "</div>"
      ],
      "id": "45896846-6d8b-48a2-8d1d-f8c7410a164f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Les résultats sont par construction mieux\n",
        "ciblés. Néanmoins ils sont toujours décevants\n",
        "puisqu’on ne parvient pas à identifier l’Insee\n",
        "dans les dix meilleurs échos."
      ],
      "id": "d22657c5-211a-4efe-bd40-3b5a9acd6c68"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "specificsearch = es.search(index = 'sirus_2020', body = \n",
        "'''{\n",
        "  \"query\": {\n",
        "    \"bool\": {\n",
        "      \"should\":\n",
        "          { \"match\": { \"rs_denom\":   \"CPCU - CENTRALE DE BERCY\"}},\n",
        "      \"filter\": [\n",
        "          {\"geo_distance\": {\n",
        "                  \"distance\": \"0.5km\",\n",
        "                  \"location\": {\n",
        "                        \"lat\": \"48.84329\", \n",
        "                        \"lon\": \"2.37396\"\n",
        "                              }\n",
        "                            }\n",
        "            }, \n",
        "            { \"prefix\":  { \"apet\": \"3530\" }}\n",
        "                ]\n",
        "            }\n",
        "          }\n",
        "}'''\n",
        ")"
      ],
      "id": "bae731b4"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/opt/conda/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  }
}